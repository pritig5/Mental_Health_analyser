{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JaSY8PmhMoK8",
    "outputId": "0fb2dd0a-52de-498a-b990-2231dd39f006",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.artist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colorbar.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, collections, cm, colors, contour, ticker\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmartist\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\collections.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_api, _path, artist, cbook, cm, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, _docstring,\n\u001b[0;32m     21\u001b[0m                hatch \u001b[38;5;28;01mas\u001b[39;00m mhatch, lines \u001b[38;5;28;01mas\u001b[39;00m mlines, path \u001b[38;5;28;01mas\u001b[39;00m mpath, transforms)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# \"color\" is excluded; it is a compound setter, and its docstring differs\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# in LineCollection.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\lines.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, _docstring\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Artist, allow_rasterization\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     _to_unmasked_float_array, ls_mapper, ls_mapper_r, STEP_LOOKUP_MAP)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarkers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MarkerStyle\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.artist'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import randint\n",
    "\n",
    "# prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "# Validation libraries\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIVsuSklXTWM",
    "outputId": "50f0e7c2-0a35-4ea7-a0e2-72fcbbde9d0e"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('survey.csv')\n",
    "print(train_df.shape)\n",
    "print(train_df.describe())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPKx4y5QX5by"
   },
   "source": [
    "#Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGGtUHo5XzvX",
    "outputId": "3747df08-d077-483a-d33e-0a28aa55dd83"
   },
   "outputs": [],
   "source": [
    "#missing data\n",
    "total = train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "EZL7prT6X-7T",
    "outputId": "9997402c-1832-4170-bf9c-a0d070f8108b"
   },
   "outputs": [],
   "source": [
    "#dealing with missing data\n",
    "train_df.drop(['comments'], axis= 1, inplace=True)\n",
    "train_df.drop(['state'], axis= 1, inplace=True)\n",
    "train_df.drop(['Timestamp'], axis= 1, inplace=True)\n",
    "\n",
    "train_df.isnull().sum().max() #just checking that there's no missing data missing...\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEJ01-IbYagP"
   },
   "source": [
    "Cleaning NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "hI4SbkGXYTp_",
    "outputId": "59835891-4d62-480d-8e89-ce156a823753"
   },
   "outputs": [],
   "source": [
    "# Assign default values for each data type\n",
    "defaultInt = 0\n",
    "defaultString = 'NaN'\n",
    "defaultFloat = 0.0\n",
    "\n",
    "# Create lists by data tpe\n",
    "intFeatures = ['Age']\n",
    "stringFeatures = ['Gender', 'Country', 'self_employed', 'family_history', 'treatment', 'work_interfere',\n",
    "                 'no_employees', 'remote_work', 'tech_company', 'anonymity', 'leave', 'mental_health_consequence',\n",
    "                 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
    "                 'mental_vs_physical', 'obs_consequence', 'benefits', 'care_options', 'wellness_program',\n",
    "                 'seek_help']\n",
    "floatFeatures = []\n",
    "\n",
    "# Clean the NaN's\n",
    "for feature in train_df:\n",
    "    if feature in intFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultInt)\n",
    "    elif feature in stringFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultString)\n",
    "    elif feature in floatFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultFloat)\n",
    "    else:\n",
    "        print('Error: Feature %s not recognized.' % feature)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAgJLUoBYzHI",
    "outputId": "624341db-ac27-479c-9b39-473cb56bde7d"
   },
   "outputs": [],
   "source": [
    "#Clean 'Gender'\n",
    "gender = train_df['Gender'].unique()\n",
    "print(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ci8qNBlHZWjt",
    "outputId": "76dccc56-193b-4c83-c4b0-9486616784c2"
   },
   "outputs": [],
   "source": [
    "#Made gender groups\n",
    "male_str = [\"male\", \"m\", \"male-ish\", \"maile\", \"mal\", \"male (cis)\", \"make\", \"male \", \"man\",\"msle\", \"mail\", \"malr\",\"cis man\", \"Cis Male\", \"cis male\"]\n",
    "trans_str = [\"trans-female\", \"something kinda male?\", \"queer/she/they\", \"non-binary\",\"nah\", \"all\", \"enby\", \"fluid\", \"genderqueer\", \"androgyne\", \"agender\", \"male leaning androgynous\", \"guy (-ish) ^_^\", \"trans woman\", \"neuter\", \"female (trans)\", \"queer\", \"ostensibly male, unsure what that really means\"]           \n",
    "female_str = [\"cis female\", \"f\", \"female\", \"woman\",  \"femake\", \"female \",\"cis-female/femme\", \"female (cis)\", \"femail\"]\n",
    "\n",
    "for (row, col) in train_df.iterrows():\n",
    "\n",
    "    if str.lower(col.Gender) in male_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='male', inplace=True)\n",
    "\n",
    "    if str.lower(col.Gender) in female_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='female', inplace=True)\n",
    "\n",
    "    if str.lower(col.Gender) in trans_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='trans', inplace=True)\n",
    "\n",
    "#Get rid of bullshit\n",
    "stk_list = ['A little about you', 'p']\n",
    "train_df = train_df[~train_df['Gender'].isin(stk_list)]\n",
    "\n",
    "print(train_df['Gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LytRp-MiZ3WM"
   },
   "outputs": [],
   "source": [
    "#complete missing age with mean\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace = True)\n",
    "\n",
    "# Fill with media() values < 18 and > 120\n",
    "s = pd.Series(train_df['Age'])\n",
    "s[s<18] = train_df['Age'].median()\n",
    "train_df['Age'] = s\n",
    "s = pd.Series(train_df['Age'])\n",
    "s[s>120] = train_df['Age'].median()\n",
    "train_df['Age'] = s\n",
    "\n",
    "#Ranges of Age\n",
    "train_df['age_range'] = pd.cut(train_df['Age'], [0,20,30,65,100], labels=[\"0-20\", \"21-30\", \"31-65\", \"66-100\"], include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-a4jIjqfaAsQ",
    "outputId": "3a9cdcc2-59bb-4752-a284-33997decf571"
   },
   "outputs": [],
   "source": [
    "#There are only 0.014% of self employed so let's change NaN to NOT self_employed\n",
    "#Replace \"NaN\" string from defaultString\n",
    "train_df['self_employed'] = train_df['self_employed'].replace([defaultString], 'No')\n",
    "print(train_df['self_employed'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlH2JMtjaI96",
    "outputId": "06884d43-f96a-4463-c306-530250947dc3"
   },
   "outputs": [],
   "source": [
    "#There are only 0.20% of self work_interfere so let's change NaN to \"Don't know\n",
    "#Replace \"NaN\" string from defaultString\n",
    "\n",
    "train_df['work_interfere'] = train_df['work_interfere'].replace([defaultString], 'Don\\'t know' )\n",
    "print(train_df['work_interfere'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vU9sRPnQaP2D"
   },
   "source": [
    "#Encoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrFCOYpSaNrL",
    "outputId": "1115893e-7b32-4c7c-cd2b-56b49fedf919"
   },
   "outputs": [],
   "source": [
    "#Encoding data\n",
    "labelDict = {}\n",
    "for feature in train_df:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_df[feature])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    train_df[feature] = le.transform(train_df[feature])\n",
    "    # Get labels\n",
    "    labelKey = 'label_' + feature\n",
    "    labelValue = [*le_name_mapping]\n",
    "    labelDict[labelKey] =labelValue\n",
    "    \n",
    "for key, value in labelDict.items():     \n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "3eBE2WLmaX96",
    "outputId": "f6495a24-b987-4ffa-ddf6-ff9ad630f33b"
   },
   "outputs": [],
   "source": [
    "#Get rid of 'Country'\n",
    "train_df = train_df.drop(['Country'], axis= 1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DNKbr_TajZa"
   },
   "source": [
    "Testing there aren't any missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxlJqy9KadVC",
    "outputId": "e0f83c12-a467-46c4-c219-e61ea021f067"
   },
   "outputs": [],
   "source": [
    "#missing data\n",
    "total = train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_df.isnull().sum()/train_df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UERrfJsnatzt"
   },
   "source": [
    "Features Scaling: We're going to scale age, because it is extremely different from the other ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoJ-Ori9avcR"
   },
   "source": [
    "#Covariance Matrix. Variability comparison between categories of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "id": "INZUJIV0antX",
    "outputId": "60085a4d-2e48-40b4-a451-99240e73e40e"
   },
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "corrmat = train_df.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "Hg1Y03-5bCVb",
    "outputId": "38e157f1-cce4-49bc-da8c-d617cb5f18a0"
   },
   "outputs": [],
   "source": [
    "#treatment correlation matrix\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'treatment')['treatment'].index\n",
    "cm = np.corrcoef(train_df[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFd3XHrUbpj_"
   },
   "source": [
    "#Some charts to see data relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf2HeCribtJ4"
   },
   "source": [
    "**Distribution** and density by Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "geuI-6OMbGez",
    "outputId": "64c7e902-2828-45ef-c799-14697fa2fa39"
   },
   "outputs": [],
   "source": [
    "# Distribution and density by Age\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df[\"Age\"], bins=24)\n",
    "plt.title(\"Distribution and density by Age\")\n",
    "plt.xlabel(\"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laO_IxDPb2cg"
   },
   "source": [
    "Separate by treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "fbpapqAAbxDh",
    "outputId": "f551fcb9-e545-4b44-e5ef-edabcc188d51"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_df, col='treatment', height=5)\n",
    "g = g.map(sns.distplot, \"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gx9Jwxbwb-Pl"
   },
   "source": [
    "How many people has been treated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "syKkijhCb5tk",
    "outputId": "6465fbf5-dff2-44f4-943d-8cef7f545e67"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "labels = labelDict['label_Gender']\n",
    "g = sns.countplot(x=\"treatment\", data=train_df)\n",
    "\n",
    "plt.title('Total Distribution by treated or not')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9h-iNvccKcD"
   },
   "source": [
    "Nested barplot to show probabilities for class and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "yZli5FghcBwt",
    "outputId": "ed3851d7-9473-4971-d62e-2daa2ab3896f"
   },
   "outputs": [],
   "source": [
    "train_df['age_range'] = train_df['age_range'].astype(str)\n",
    "train_df['Gender'] = train_df['Gender'].astype(str)\n",
    "o = labelDict['label_age_range']\n",
    "\n",
    "g = sns.catplot(x=\"age_range\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\",  errorbar=None, height=5, aspect=2, legend_out = True)\n",
    "g.set_xticklabels(o)\n",
    "\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Age')\n",
    "# replace legend labels\n",
    "\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "# Positioning the legend\n",
    "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmthbxoXcYE1"
   },
   "source": [
    "Barplot to show probabilities for family history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "UoUsvFVRcPe2",
    "outputId": "54879c9e-a8c4-4e5c-cfc5-93c9af4ed62c"
   },
   "outputs": [],
   "source": [
    "o = labelDict['label_family_history']\n",
    "g = sns.catplot(x=\"family_history\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", errorbar=None, height=5, aspect=2, legend_out = True)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Family History')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "# Positioning the legend\n",
    "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fqj4LICwcgrN"
   },
   "source": [
    "Barplot to show probabilities for care options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "pKB-tQO3cbq_",
    "outputId": "b5a5748c-bfac-4619-b393-1bbf997e1271"
   },
   "outputs": [],
   "source": [
    "o = labelDict['label_care_options']\n",
    "g = sns.catplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", errorbar=None, height=5, aspect=2, legend_out = True)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Care options')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "# Positioning the legend\n",
    "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oukVHMQwcozL"
   },
   "source": [
    "Barplot to show probabilities for benefits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "cW3ykFSYckMt",
    "outputId": "99658ce7-d4a4-46b6-a0ed-62b6a6368740"
   },
   "outputs": [],
   "source": [
    "o = labelDict['label_benefits']\n",
    "g = sns.catplot(x=\"care_options\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", errorbar=None, height=5, aspect=2, legend_out = True)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Benefits')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "# Positioning the legend\n",
    "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6CnGdrrcwqU"
   },
   "source": [
    "Barplot to show probabilities for work interfere\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "RQVddZv3ctIZ",
    "outputId": "9f28883b-8b00-467d-cd55-8cc97f7cd8ca"
   },
   "outputs": [],
   "source": [
    "o = labelDict['label_work_interfere']\n",
    "g = sns.catplot(x=\"work_interfere\", y=\"treatment\", hue=\"Gender\", data=train_df, kind=\"bar\", errorbar=None, height=5, aspect=2, legend_out = True)\n",
    "g.set_xticklabels(o)\n",
    "plt.title('Probability of mental health condition')\n",
    "plt.ylabel('Probability x 100')\n",
    "plt.xlabel('Work interfere')\n",
    "\n",
    "# replace legend labels\n",
    "new_labels = labelDict['label_Gender']\n",
    "for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "# Positioning the legend\n",
    "g.fig.subplots_adjust(top=0.9,right=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaJjYfbtc7S3"
   },
   "source": [
    "#Scaling and Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSN4p5CWc_4z"
   },
   "source": [
    "Features Scaling We're going to scale age, because is extremely different from the othere ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "E8CEx69mc0Ff",
    "outputId": "d631bcaf-402c-48ff-fd6d-aee434e81b8e"
   },
   "outputs": [],
   "source": [
    "# Scaling Age\n",
    "scaler = MinMaxScaler()\n",
    "train_df['Age'] = scaler.fit_transform(train_df[['Age']])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emP7M76leCr2"
   },
   "source": [
    "Spilitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4PCK9kudFlM"
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['Age', 'Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere']\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.treatment\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Create dictionaries for final graph\n",
    "# Use: methodDict['Stacking'] = accuracy_score\n",
    "methodDict = {}\n",
    "rmseDict = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "DJ-Fn4EeeJ7v",
    "outputId": "df7dea02-3bd8-421b-8b75-7c91a01f1605"
   },
   "outputs": [],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "labels = []\n",
    "for f in range(X.shape[1]):\n",
    "    labels.append(feature_cols[f])      \n",
    "    \n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), labels, rotation='vertical')\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2wG6BfSeSVo"
   },
   "source": [
    "#Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqq2ECp2eOKh"
   },
   "outputs": [],
   "source": [
    "def evalClassModel(model, y_test, y_pred_class, plot=False):\n",
    "    #Classification accuracy: percentage of correct predictions\n",
    "    # calculate accuracy\n",
    "    print('Accuracy:', metrics.accuracy_score(y_test, y_pred_class))\n",
    "    \n",
    "    #Null accuracy: accuracy that could be achieved by always predicting the most frequent class\n",
    "    # examine the class distribution of the testing set (using a Pandas Series method)\n",
    "    print('Null accuracy:\\n', y_test.value_counts())\n",
    "    \n",
    "    # calculate the percentage of ones\n",
    "    print('Percentage of ones:', y_test.mean())\n",
    "    \n",
    "    # calculate the percentage of zeros\n",
    "    print('Percentage of zeros:',1 - y_test.mean())\n",
    "    \n",
    "    #Comparing the true and predicted response values\n",
    "    print('True:', y_test.values[0:25])\n",
    "    print('Pred:', y_pred_class[0:25])\n",
    "    \n",
    "    #Confusion matrix\n",
    "    # save confusion matrix and slice into four pieces\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "    #[row, column]\n",
    "    TP = confusion[1, 1]\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    \n",
    "    # visualize Confusion Matrix\n",
    "    sns.heatmap(confusion,annot=True,fmt=\"d\") \n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    #Metrics computed from a confusion matrix\n",
    "    #Classification Accuracy: Overall, how often is the classifier correct?\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    print('Classification Accuracy:', accuracy)\n",
    "    \n",
    "    #Classification Error: Overall, how often is the classifier incorrect?\n",
    "    print('Classification Error:', 1 - metrics.accuracy_score(y_test, y_pred_class))\n",
    "    \n",
    "    #False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n",
    "    false_positive_rate = FP / float(TN + FP)\n",
    "    print('False Positive Rate:', false_positive_rate)\n",
    "    \n",
    "    #Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "    print('Precision:', metrics.precision_score(y_test, y_pred_class))\n",
    "    \n",
    "    \n",
    "    # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "    print('AUC Score:', metrics.roc_auc_score(y_test, y_pred_class))\n",
    "    \n",
    "    # calculate cross-validated AUC\n",
    "    print('Cross-validated AUC:', cross_val_score(model, X, y, cv=10, scoring='roc_auc').mean())\n",
    "    \n",
    "    ##########################################\n",
    "    #Adjusting the classification threshold\n",
    "    ##########################################\n",
    "    # print the first 10 predicted responses\n",
    "    print('First 10 predicted responses:\\n', model.predict(X_test)[0:10])\n",
    "\n",
    "    # print the first 10 predicted probabilities of class membership\n",
    "    print('First 10 predicted probabilities of class members:\\n', model.predict_proba(X_test)[0:10])\n",
    "\n",
    "    # print the first 10 predicted probabilities for class 1\n",
    "    model.predict_proba(X_test)[0:10, 1]\n",
    "    \n",
    "    # store the predicted probabilities for class 1\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    if plot == True:\n",
    "        # histogram of predicted probabilities\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        plt.hist(y_pred_prob, bins=8)\n",
    "        \n",
    "        # x-axis limit from 0 to 1\n",
    "        plt.xlim(0,1)\n",
    "        plt.title('Histogram of predicted probabilities')\n",
    "        plt.xlabel('Predicted probability of treatment')\n",
    "        plt.ylabel('Frequency')\n",
    "    \n",
    "    \n",
    "    # predict treatment if the predicted probability is greater than 0.3\n",
    "    # it will return 1 for all values above 0.3 and 0 otherwise\n",
    "    # results are 2D so we slice out the first column\n",
    "    y_pred_prob = y_pred_prob.reshape(-1,1) \n",
    "    threshold = 0.3\n",
    "    y_pred_class = binarize(y_pred_prob, threshold=threshold)\n",
    "    #y_pred_class = binarize(y_pred_prob, 0.3)[0]\n",
    "    \n",
    "    # print the first 10 predicted probabilities\n",
    "    print('First 10 predicted probabilities:\\n', y_pred_prob[0:10])\n",
    "    \n",
    "    ##########################################\n",
    "    #ROC Curves and Area Under the Curve (AUC)\n",
    "    ##########################################\n",
    "    \n",
    "    #AUC is the percentage of the ROC plot that is underneath the curve\n",
    "    #Higher value = better classifier\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    \n",
    "\n",
    "    # IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "    # roc_curve returns 3 objects fpr, tpr, thresholds\n",
    "    # fpr: false positive rate\n",
    "    # tpr: true positive rate\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "    if plot == True:\n",
    "        plt.figure()\n",
    "        \n",
    "        plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        plt.title('ROC curve for treatment classifier')\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    # define a function that accepts a threshold and prints sensitivity and specificity\n",
    "    def evaluate_threshold(threshold):\n",
    "        #Sensitivity: When the actual value is positive, how often is the prediction correct?\n",
    "        #Specificity: When the actual value is negative, how often is the prediction correct?print('Sensitivity for ' + str(threshold) + ' :', tpr[thresholds > threshold][-1])\n",
    "        print('Specificity for ' + str(threshold) + ' :', 1 - fpr[thresholds > threshold][-1])\n",
    "\n",
    "    # One way of setting threshold\n",
    "    predict_mine = np.where(y_pred_prob > 0.50, 1, 0)\n",
    "    confusion = metrics.confusion_matrix(y_test, predict_mine)\n",
    "    print(confusion)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7tGbmc4fW9C"
   },
   "source": [
    "Tuning with cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9Y7NReefTiV"
   },
   "outputs": [],
   "source": [
    "def tuningCV(knn):\n",
    "    \n",
    "    # search for an optimal value of K for KNN\n",
    "    k_range = list(range(1, 31))\n",
    "    k_scores = []\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "        k_scores.append(scores.mean())\n",
    "    print(k_scores)\n",
    "    # plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "    plt.plot(k_range, k_scores)\n",
    "    plt.xlabel('Value of K for KNN')\n",
    "    plt.ylabel('Cross-Validated Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYytocEofeOE"
   },
   "source": [
    "Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjE6ARIYfbkd"
   },
   "outputs": [],
   "source": [
    "def tuningGridSerach(knn):\n",
    "    #More efficient parameter tuning using GridSearchCV\n",
    "    k_range = list(range(1, 31))\n",
    "    print(k_range)\n",
    "    \n",
    "    # create a parameter grid: map the parameter names to the values that should be searched\n",
    "    param_grid = dict(n_neighbors=k_range)\n",
    "    print(param_grid)\n",
    "    \n",
    "    # instantiate the grid\n",
    "    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "    # fit the grid with data\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    # view the complete results (list of named tuples)\n",
    "    grid.grid_scores_\n",
    "    \n",
    "    # examine the first tuple\n",
    "    print(grid.grid_scores_[0].parameters)\n",
    "    print(grid.grid_scores_[0].cv_validation_scores)\n",
    "    print(grid.grid_scores_[0].mean_validation_score)\n",
    "    \n",
    "    # create a list of the mean scores only\n",
    "    grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]\n",
    "    print(grid_mean_scores)\n",
    "    \n",
    "    # plot the results\n",
    "    plt.plot(k_range, grid_mean_scores)\n",
    "    plt.xlabel('Value of K for KNN')\n",
    "    plt.ylabel('Cross-Validated Accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    # examine the best model\n",
    "    print('GridSearch best score', grid.best_score_)\n",
    "    print('GridSearch best params', grid.best_params_)\n",
    "    print('GridSearch best estimator', grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFhg6D_wfrUt"
   },
   "source": [
    "Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrfBM1XUfoxf"
   },
   "outputs": [],
   "source": [
    "def tuningRandomizedSearchCV(model, param_dist):\n",
    "    #Searching multiple parameters simultaneously\n",
    "    # n_iter controls the number of searches\n",
    "    rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "    rand.fit(X, y)\n",
    "    rand.cv_results_\n",
    "    \n",
    "    # examine the best model\n",
    "    print('Rand. Best Score: ', rand.best_score_)\n",
    "    print('Rand. Best Params: ', rand.best_params_)\n",
    "    \n",
    "    # run RandomizedSearchCV 20 times (with n_iter=10) and record the best score\n",
    "    best_scores = []\n",
    "    for _ in range(20):\n",
    "        rand = RandomizedSearchCV(model, param_dist, cv=10, scoring='accuracy', n_iter=10)\n",
    "        rand.fit(X, y)\n",
    "        best_scores.append(round(rand.best_score_, 3))\n",
    "    print(best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzaS7F-vfzeV"
   },
   "source": [
    "Tuning with searching multiple parameters simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeSKD8Abfw94"
   },
   "outputs": [],
   "source": [
    "def tuningMultParam(knn):\n",
    "    \n",
    "    #Searching multiple parameters simultaneously\n",
    "    # define the parameter values that should be searched\n",
    "    k_range = list(range(1, 31))\n",
    "    weight_options = ['uniform', 'distance']\n",
    "        \n",
    "    # create a parameter grid: map the parameter names to the values that should be searched\n",
    "    param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "    print(param_grid) \n",
    "    \n",
    "    # instantiate and fit the grid\n",
    "    grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "    grid.fit(X, y) \n",
    "    \n",
    "    # view the complete results\n",
    "    print(grid.grid_scores_)\n",
    "    \n",
    "    # examine the best model\n",
    "    print('Multiparam. Best Score: ', grid.best_score_)\n",
    "    print('Multiparam. Best Params: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNWD9dq3f8Ef"
   },
   "source": [
    "#Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f2FmsFZf94S"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMZS5dMKf5vw"
   },
   "outputs": [],
   "source": [
    "def logisticRegression():\n",
    "    # train a logistic regression model on the training set\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    # make class predictions for the testing set\n",
    "    y_pred_class = logreg.predict(X_test)\n",
    "    \n",
    "    accuracy_score = evalClassModel(logreg, y_test, y_pred_class, True)\n",
    "    \n",
    "    #Data for final graph\n",
    "    methodDict['Log. Regression'] = accuracy_score * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LGt-pyy9gHF1",
    "outputId": "d78f7efd-6448-4018-fa6d-8b5125727b92"
   },
   "outputs": [],
   "source": [
    "logisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPH7c5ozgQrQ"
   },
   "source": [
    "KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIIpZmUkgKhz"
   },
   "outputs": [],
   "source": [
    "def Knn():\n",
    "    # Calculating the best parameters\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    # define the parameter values that should be searched\n",
    "    k_range = list(range(1, 31))\n",
    "    weight_options = ['uniform', 'distance']\n",
    "    \n",
    "    # specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "    param_dist = dict(n_neighbors=k_range, weights=weight_options)\n",
    "    tuningRandomizedSearchCV(knn, param_dist)\n",
    "    \n",
    "    # train a KNeighborsClassifier model on the training set\n",
    "    knn = KNeighborsClassifier(n_neighbors=27, weights='uniform')\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # make class predictions for the testing set\n",
    "    y_pred_class = knn.predict(X_test)\n",
    "    \n",
    "    accuracy_score = evalClassModel(knn, y_test, y_pred_class, True)\n",
    "\n",
    "    #Data for final graph\n",
    "    methodDict['K-Neighbors'] = accuracy_score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NndcXu8LgcPZ",
    "outputId": "d159c597-893f-4314-8053-d02e3928926c"
   },
   "outputs": [],
   "source": [
    "Knn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATF-3ODii6IE"
   },
   "source": [
    "Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrbzKiXQgfIk"
   },
   "outputs": [],
   "source": [
    "def treeClassifier():\n",
    "    # Calculating the best parameters\n",
    "    tree = DecisionTreeClassifier()\n",
    "    featuresSize = feature_cols.__len__()\n",
    "    param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, featuresSize),\n",
    "              \"min_samples_split\": randint(2, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    tuningRandomizedSearchCV(tree, param_dist)\n",
    "    \n",
    "    # train a decision tree model on the training set\n",
    "    tree = DecisionTreeClassifier(max_depth=3, min_samples_split=8, max_features=6, criterion='entropy', min_samples_leaf=7)\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # make class predictions for the testing set\n",
    "    y_pred_class = tree.predict(X_test)\n",
    "    \n",
    "    accuracy_score = evalClassModel(tree, y_test, y_pred_class, True)\n",
    "\n",
    "    #Data for final graph\n",
    "    methodDict['Decision Tree Classifier'] = accuracy_score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "emMSj1I4jAus",
    "outputId": "ef544193-0a5d-4ea0-c1b7-ab77bdcb6f6c"
   },
   "outputs": [],
   "source": [
    "treeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkOs4a2ajLaM"
   },
   "source": [
    "Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pLiMXGZjFgC"
   },
   "outputs": [],
   "source": [
    "def randomForest():\n",
    "    # Calculating the best parameters\n",
    "    forest = RandomForestClassifier(n_estimators = 20)\n",
    "\n",
    "    featuresSize = feature_cols.__len__()\n",
    "    param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, featuresSize),\n",
    "              \"min_samples_split\": randint(2, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "    tuningRandomizedSearchCV(forest, param_dist)\n",
    "    \n",
    "    # Building and fitting my_forest\n",
    "    forest = RandomForestClassifier(max_depth = None, min_samples_leaf=8, min_samples_split=2, n_estimators = 20, random_state = 1)\n",
    "    my_forest = forest.fit(X_train, y_train)\n",
    "    \n",
    "    # make class predictions for the testing set\n",
    "    y_pred_class = my_forest.predict(X_test)\n",
    "    \n",
    "    accuracy_score = evalClassModel(my_forest, y_test, y_pred_class, True)\n",
    "\n",
    "    #Data for final graph\n",
    "    methodDict['Random Forest'] = accuracy_score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2ewO8zkNjc9i",
    "outputId": "f20fc084-f97d-479f-a108-5484a02b1536"
   },
   "outputs": [],
   "source": [
    "randomForest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-3ZMNTqkyzV"
   },
   "source": [
    "#Predicting with Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CudEize4lINa"
   },
   "source": [
    "Create input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uV5cCeJuku5Y",
    "outputId": "05a399aa-cacd-414f-9c11-e0dad5163005"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVaBMhL3orLQ",
    "outputId": "dab110b4-b3b5-420d-8612-2d4426454a5c"
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "052nJ7QslObk"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_steps = 1000\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    return dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    features=dict(features)\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxxCxpSGlmJh"
   },
   "source": [
    "Define the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R61A8-p5lZg3"
   },
   "outputs": [],
   "source": [
    "# Define Tensorflow feature columns\n",
    "age = tf.feature_column.numeric_column(\"Age\")\n",
    "gender = tf.feature_column.numeric_column(\"Gender\")\n",
    "family_history = tf.feature_column.numeric_column(\"family_history\")\n",
    "benefits = tf.feature_column.numeric_column(\"benefits\")\n",
    "care_options = tf.feature_column.numeric_column(\"care_options\")\n",
    "anonymity = tf.feature_column.numeric_column(\"anonymity\")\n",
    "leave = tf.feature_column.numeric_column(\"leave\")\n",
    "work_interfere = tf.feature_column.numeric_column(\"work_interfere\")\n",
    "feature_columns = [age, gender, family_history, benefits, care_options, anonymity, leave, work_interfere]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iom0cxX3lvIv"
   },
   "source": [
    "Instantiate an Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VL70hhsblplj",
    "outputId": "97f009d3-d1a2-4734-f97d-d76ccfbe3783"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Ensure data types are correct\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)  # or np.int32 for classification\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)  # or np.int32 for classification\n",
    "\n",
    "# Define TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)\n",
    "\n",
    "# Define and compile the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # For binary classification\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1),\n",
    "    loss='binary_crossentropy',  # For binary classification\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = model.evaluate(test_dataset)\n",
    "\n",
    "# Print the results\n",
    "accuracy = eval_result[1] * 100  # Assuming accuracy is the second element\n",
    "print('\\nTest set accuracy: {:.2f}\\n'.format(accuracy))\n",
    "\n",
    "# Data for final graph\n",
    "methodDict['Neural Network'] = accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThzYnW6MqU27"
   },
   "source": [
    "Making predictions (inferring) from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uU3dQmR6qQmy",
    "outputId": "83ee14a0-d187-43ec-fb50-b1b343806a9a"
   },
   "outputs": [],
   "source": [
    "# Ensure data types are correct\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "\n",
    "# Define TensorFlow dataset (if needed)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(X_test).batch(batch_size)\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to a list (if necessary)\n",
    "predictions = list(predictions)\n",
    "\n",
    "# Example: If your output layer uses sigmoid activation for binary classification\n",
    "predictions = [1 if p > 0.5 else 0 for p in predictions]  # Thresholding for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "-v8sJZumqXhr",
    "outputId": "5ed19e71-baf8-41ef-bfe9-8920030f9f4a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Generate predictions from the model\n",
    "predictions = model.predict(X_train)  # Assuming X_train is your test data\n",
    "\n",
    "# Template for printing results\n",
    "template = ('\\nIndex: \"{}\", Prediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "# Dictionary for predictions\n",
    "col1 = []\n",
    "col2 = []\n",
    "col3 = []\n",
    "\n",
    "# Create an index array\n",
    "indices = np.arange(len(X_train))\n",
    "\n",
    "# Process predictions\n",
    "for idx, input, p in zip(indices, y_train, predictions):\n",
    "    # Assuming multi-class classification with probabilities\n",
    "    class_id = np.argmax(p)  # For multi-class, get the class with the highest probability\n",
    "    probability = p[class_id]  # Probability for the predicted class\n",
    "\n",
    "    # Adding to lists\n",
    "    col1.append(idx)  # Index\n",
    "    col2.append(class_id)  # Prediction (class label)\n",
    "    col3.append(input)  # Expected\n",
    "\n",
    "    # Print results\n",
    "\n",
    "# Create DataFrame from results\n",
    "results = pd.DataFrame({'index': col1, 'prediction': col2, 'expected': col3})\n",
    "print(results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhxYxHNBqdxr"
   },
   "source": [
    "#Success method plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMSTgbylqbqB"
   },
   "outputs": [],
   "source": [
    "def plotSuccess():\n",
    "    s = pd.Series(methodDict)\n",
    "    s = s.sort_values(ascending=False)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    #Colors\n",
    "    ax = s.plot(kind='bar') \n",
    "    for p in ax.patches:\n",
    "        ax.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "    plt.ylim([70.0, 90.0])\n",
    "    plt.xlabel('Method')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.title('Success of methods')\n",
    "     \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "HQr49POJqjaB",
    "outputId": "c5c9d0a5-3d58-48ca-8d6e-db6ae5ca9f1f"
   },
   "outputs": [],
   "source": [
    "plotSuccess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(methodDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "TIP_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
